{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:32:18.265798Z",
     "iopub.status.busy": "2021-07-12T02:32:18.265478Z",
     "iopub.status.idle": "2021-07-12T02:32:32.235749Z",
     "shell.execute_reply": "2021-07-12T02:32:32.234779Z",
     "shell.execute_reply.started": "2021-07-12T02:32:18.265769Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:32:32.237968Z",
     "iopub.status.busy": "2021-07-12T02:32:32.237595Z",
     "iopub.status.idle": "2021-07-12T02:32:32.902259Z",
     "shell.execute_reply": "2021-07-12T02:32:32.901318Z",
     "shell.execute_reply.started": "2021-07-12T02:32:32.237915Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:32:32.90453Z",
     "iopub.status.busy": "2021-07-12T02:32:32.904187Z",
     "iopub.status.idle": "2021-07-12T02:33:05.267536Z",
     "shell.execute_reply": "2021-07-12T02:33:05.266486Z",
     "shell.execute_reply.started": "2021-07-12T02:32:32.904493Z"
    }
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import numpy as np\n",
    "path = r'F:\\rzbz\\Leuk study re-designed\\ALLIDB-2\\High imbalance\\Train - 1 to 100 ratio\\all'\n",
    "all_list = os.listdir(path)\n",
    "\n",
    "train_data = np.zeros((len(all_list), 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "index = 0\n",
    "for x in range(len(all_list)):\n",
    "    img = imread(os.path.join(path, all_list[x]))\n",
    "    img = resize(img, (256,256,3), preserve_range=True,  mode='constant')\n",
    "    train_data[index] = img\n",
    "    index+=1\n",
    "print(train_data.shape)\n",
    "print(type(train_data))\n",
    "# print(train_data.dtype)\n",
    "# train_data = train_data / 255.0\n",
    "# print(np.unique(train_data))\n",
    "# print(train_data.dtype)\n",
    "# train_data = train_data.astype('float32')\n",
    "# print(train_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:05.272921Z",
     "iopub.status.busy": "2021-07-12T02:33:05.272502Z",
     "iopub.status.idle": "2021-07-12T02:33:05.481372Z",
     "shell.execute_reply": "2021-07-12T02:33:05.480501Z",
     "shell.execute_reply.started": "2021-07-12T02:33:05.272879Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_all = tf.data.Dataset.from_tensor_slices((train_data))\n",
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:05.483626Z",
     "iopub.status.busy": "2021-07-12T02:33:05.483143Z",
     "iopub.status.idle": "2021-07-12T02:33:22.83608Z",
     "shell.execute_reply": "2021-07-12T02:33:22.835115Z",
     "shell.execute_reply.started": "2021-07-12T02:33:05.483574Z"
    }
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.io import imshow, imread\n",
    "import os\n",
    "import numpy as np\n",
    "path = r'F:\\rzbz\\Leuk study re-designed\\ALLIDB-2\\High imbalance\\Train - 1 to 100 ratio\\hem'\n",
    "hem_list = os.listdir(path)\n",
    "\n",
    "train_data = np.zeros((len(hem_list), 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "index = 0\n",
    "for x in range(len(hem_list)):\n",
    "    img = imread(os.path.join(path, hem_list[x]))\n",
    "    img = resize(img, (256,256,3), preserve_range=True,  mode='constant')\n",
    "    train_data[index] = img\n",
    "    index+=1\n",
    "print(train_data.shape)\n",
    "print(type(train_data))\n",
    "# print(train_data.dtype)\n",
    "# train_data = train_data / 255.0\n",
    "# print(np.unique(train_data))\n",
    "# print(train_data.dtype)\n",
    "# train_data = train_data.astype('float32')\n",
    "# print(train_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:22.838438Z",
     "iopub.status.busy": "2021-07-12T02:33:22.837758Z",
     "iopub.status.idle": "2021-07-12T02:33:22.968343Z",
     "shell.execute_reply": "2021-07-12T02:33:22.967288Z",
     "shell.execute_reply.started": "2021-07-12T02:33:22.838392Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_hem = tf.data.Dataset.from_tensor_slices((train_data))\n",
    "train_hem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:22.970068Z",
     "iopub.status.busy": "2021-07-12T02:33:22.969707Z",
     "iopub.status.idle": "2021-07-12T02:33:22.976955Z",
     "shell.execute_reply": "2021-07-12T02:33:22.976147Z",
     "shell.execute_reply.started": "2021-07-12T02:33:22.970028Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH =  256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:22.980911Z",
     "iopub.status.busy": "2021-07-12T02:33:22.980521Z",
     "iopub.status.idle": "2021-07-12T02:33:22.9857Z",
     "shell.execute_reply": "2021-07-12T02:33:22.984513Z",
     "shell.execute_reply.started": "2021-07-12T02:33:22.980873Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:22.988707Z",
     "iopub.status.busy": "2021-07-12T02:33:22.987977Z",
     "iopub.status.idle": "2021-07-12T02:33:22.994109Z",
     "shell.execute_reply": "2021-07-12T02:33:22.992987Z",
     "shell.execute_reply.started": "2021-07-12T02:33:22.988668Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:22.995855Z",
     "iopub.status.busy": "2021-07-12T02:33:22.995461Z",
     "iopub.status.idle": "2021-07-12T02:33:23.001774Z",
     "shell.execute_reply": "2021-07-12T02:33:23.00083Z",
     "shell.execute_reply.started": "2021-07-12T02:33:22.995817Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_jitter(image):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image)\n",
    "\n",
    "  # random mirroring\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:23.003684Z",
     "iopub.status.busy": "2021-07-12T02:33:23.003131Z",
     "iopub.status.idle": "2021-07-12T02:33:23.011128Z",
     "shell.execute_reply": "2021-07-12T02:33:23.010287Z",
     "shell.execute_reply.started": "2021-07-12T02:33:23.003646Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "  image = random_jitter(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:23.012888Z",
     "iopub.status.busy": "2021-07-12T02:33:23.012465Z",
     "iopub.status.idle": "2021-07-12T02:33:23.018883Z",
     "shell.execute_reply": "2021-07-12T02:33:23.018021Z",
     "shell.execute_reply.started": "2021-07-12T02:33:23.012853Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image_test(image):\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:23.020785Z",
     "iopub.status.busy": "2021-07-12T02:33:23.020219Z",
     "iopub.status.idle": "2021-07-12T02:33:23.258212Z",
     "shell.execute_reply": "2021-07-12T02:33:23.257427Z",
     "shell.execute_reply.started": "2021-07-12T02:33:23.020746Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all = train_all.cache().map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_hem = train_hem.cache().map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# test_horses = test_horses.map(\n",
    "#     preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "#     BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# test_zebras = test_zebras.map(\n",
    "#     preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "#     BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:23.259699Z",
     "iopub.status.busy": "2021-07-12T02:33:23.259364Z",
     "iopub.status.idle": "2021-07-12T02:33:23.266587Z",
     "shell.execute_reply": "2021-07-12T02:33:23.265578Z",
     "shell.execute_reply.started": "2021-07-12T02:33:23.259665Z"
    }
   },
   "outputs": [],
   "source": [
    "train_hem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:23.268143Z",
     "iopub.status.busy": "2021-07-12T02:33:23.267782Z",
     "iopub.status.idle": "2021-07-12T02:33:27.596375Z",
     "shell.execute_reply": "2021-07-12T02:33:27.595512Z",
     "shell.execute_reply.started": "2021-07-12T02:33:23.268107Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_all = next(iter(train_all))\n",
    "sample_hem = next(iter(train_hem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:27.599759Z",
     "iopub.status.busy": "2021-07-12T02:33:27.599492Z",
     "iopub.status.idle": "2021-07-12T02:33:27.825998Z",
     "shell.execute_reply": "2021-07-12T02:33:27.825246Z",
     "shell.execute_reply.started": "2021-07-12T02:33:27.599734Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.io import imshow, imread\n",
    "print(type(sample_all))\n",
    "img = sample_all.numpy()\n",
    "print('Before slicing: ', img.shape)\n",
    "img = img[0,:,:,:]\n",
    "img = img * 0.5 + 0.5\n",
    "print('After slicing: ', img.shape)\n",
    "print(np.unique(img))\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:27.827571Z",
     "iopub.status.busy": "2021-07-12T02:33:27.827227Z",
     "iopub.status.idle": "2021-07-12T02:33:28.511842Z",
     "shell.execute_reply": "2021-07-12T02:33:28.51104Z",
     "shell.execute_reply.started": "2021-07-12T02:33:27.827535Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('All')\n",
    "plt.imshow(sample_all[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('All with random jitter')\n",
    "plt.imshow(random_jitter(sample_all[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:28.513795Z",
     "iopub.status.busy": "2021-07-12T02:33:28.513238Z",
     "iopub.status.idle": "2021-07-12T02:33:28.777836Z",
     "shell.execute_reply": "2021-07-12T02:33:28.777084Z",
     "shell.execute_reply.started": "2021-07-12T02:33:28.513755Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Hem')\n",
    "plt.imshow(sample_hem[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Hem with random jitter')\n",
    "plt.imshow(random_jitter(sample_hem[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:28.77935Z",
     "iopub.status.busy": "2021-07-12T02:33:28.779003Z",
     "iopub.status.idle": "2021-07-12T02:33:30.185619Z",
     "shell.execute_reply": "2021-07-12T02:33:30.184774Z",
     "shell.execute_reply.started": "2021-07-12T02:33:28.779319Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:30.187245Z",
     "iopub.status.busy": "2021-07-12T02:33:30.186897Z",
     "iopub.status.idle": "2021-07-12T02:33:36.52605Z",
     "shell.execute_reply": "2021-07-12T02:33:36.525216Z",
     "shell.execute_reply.started": "2021-07-12T02:33:30.187211Z"
    }
   },
   "outputs": [],
   "source": [
    "to_hem = generator_g(sample_all)\n",
    "to_all = generator_f(sample_hem)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_all, to_hem, sample_hem, to_all]\n",
    "title = ['All', 'To Hem', 'Hem', 'To All']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  plt.title(title[i])\n",
    "  if i % 2 == 0:\n",
    "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "  else:\n",
    "    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.527628Z",
     "iopub.status.busy": "2021-07-12T02:33:36.527274Z",
     "iopub.status.idle": "2021-07-12T02:33:36.771339Z",
     "shell.execute_reply": "2021-07-12T02:33:36.770353Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.527584Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Is a real hem?')\n",
    "plt.imshow(discriminator_y(sample_hem)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Is a real all?')\n",
    "plt.imshow(discriminator_x(sample_all)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.773138Z",
     "iopub.status.busy": "2021-07-12T02:33:36.772791Z",
     "iopub.status.idle": "2021-07-12T02:33:36.777233Z",
     "shell.execute_reply": "2021-07-12T02:33:36.77627Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.773101Z"
    }
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "\n",
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.781672Z",
     "iopub.status.busy": "2021-07-12T02:33:36.781187Z",
     "iopub.status.idle": "2021-07-12T02:33:36.787613Z",
     "shell.execute_reply": "2021-07-12T02:33:36.786867Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.781634Z"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "  real_loss = loss_obj(tf.ones_like(real), real)\n",
    "\n",
    "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.789715Z",
     "iopub.status.busy": "2021-07-12T02:33:36.789297Z",
     "iopub.status.idle": "2021-07-12T02:33:36.797176Z",
     "shell.execute_reply": "2021-07-12T02:33:36.796376Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.789676Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "  return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.798792Z",
     "iopub.status.busy": "2021-07-12T02:33:36.798281Z",
     "iopub.status.idle": "2021-07-12T02:33:36.806569Z",
     "shell.execute_reply": "2021-07-12T02:33:36.80573Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.798757Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "  return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.809642Z",
     "iopub.status.busy": "2021-07-12T02:33:36.808977Z",
     "iopub.status.idle": "2021-07-12T02:33:36.814979Z",
     "shell.execute_reply": "2021-07-12T02:33:36.814212Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.809469Z"
    }
   },
   "outputs": [],
   "source": [
    "def identity_loss(real_image, same_image):\n",
    "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "  return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.816709Z",
     "iopub.status.busy": "2021-07-12T02:33:36.81633Z",
     "iopub.status.idle": "2021-07-12T02:33:36.82469Z",
     "shell.execute_reply": "2021-07-12T02:33:36.823769Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.816671Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.82778Z",
     "iopub.status.busy": "2021-07-12T02:33:36.827489Z",
     "iopub.status.idle": "2021-07-12T02:33:36.835911Z",
     "shell.execute_reply": "2021-07-12T02:33:36.835127Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.827754Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = r\"F:\\rzbz\\Leuk study re-designed\\ALLIDB-2\\High imbalance\\chkpnt\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.837802Z",
     "iopub.status.busy": "2021-07-12T02:33:36.837227Z",
     "iopub.status.idle": "2021-07-12T02:33:36.847193Z",
     "shell.execute_reply": "2021-07-12T02:33:36.846263Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.837764Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "def generate_images(model, test_input):\n",
    "  prediction = model(test_input)\n",
    "\n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "  display_list = [test_input[0], prediction[0]]\n",
    "  title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "  for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.850128Z",
     "iopub.status.busy": "2021-07-12T02:33:36.849743Z",
     "iopub.status.idle": "2021-07-12T02:33:36.863289Z",
     "shell.execute_reply": "2021-07-12T02:33:36.862421Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.85009Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "  # persistent is set to True because the tape is used more than\n",
    "  # once to calculate the gradients.\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "    # Generator G translates X -> Y\n",
    "    # Generator F translates Y -> X.\n",
    "\n",
    "    fake_y = generator_g(real_x, training=True)\n",
    "    cycled_x = generator_f(fake_y, training=True)\n",
    "\n",
    "    fake_x = generator_f(real_y, training=True)\n",
    "    cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "    # same_x and same_y are used for identity loss.\n",
    "    same_x = generator_f(real_x, training=True)\n",
    "    same_y = generator_g(real_y, training=True)\n",
    "\n",
    "    disc_real_x = discriminator_x(real_x, training=True)\n",
    "    disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "    # calculate the loss\n",
    "    gen_g_loss = generator_loss(disc_fake_y)\n",
    "    gen_f_loss = generator_loss(disc_fake_x)\n",
    "\n",
    "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "\n",
    "    # Total generator loss = adversarial loss + cycle loss\n",
    "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "\n",
    "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "\n",
    "  # Calculate the gradients for generator and discriminator\n",
    "  generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                        generator_g.trainable_variables)\n",
    "  generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "\n",
    "  discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "  discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "\n",
    "  # Apply the gradients to the optimizer\n",
    "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "\n",
    "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "\n",
    "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T02:33:36.865363Z",
     "iopub.status.busy": "2021-07-12T02:33:36.864903Z",
     "iopub.status.idle": "2021-07-12T04:11:54.801715Z",
     "shell.execute_reply": "2021-07-12T04:11:54.800821Z",
     "shell.execute_reply.started": "2021-07-12T02:33:36.865326Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  n = 0\n",
    "  for image_x, image_y in tf.data.Dataset.zip((train_all, train_hem)):\n",
    "    train_step(image_x, image_y)\n",
    "    if n % 10 == 0:\n",
    "      print ('.', end='')\n",
    "    n += 1\n",
    "\n",
    "  clear_output(wait=True)\n",
    "  # Using a consistent image (sample_horse) so that the progress of the model\n",
    "  # is clearly visible.\n",
    "  generate_images(generator_g, sample_all)\n",
    "\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "\n",
    "  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                      time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T04:33:48.351482Z",
     "iopub.status.busy": "2021-07-12T04:33:48.351152Z",
     "iopub.status.idle": "2021-07-12T04:33:48.356037Z",
     "shell.execute_reply": "2021-07-12T04:33:48.35518Z",
     "shell.execute_reply.started": "2021-07-12T04:33:48.351451Z"
    }
   },
   "outputs": [],
   "source": [
    "#EPOCHS = 40\n",
    "\n",
    "def generate_images(model, test_input):\n",
    "  prediction = model(test_input)\n",
    "  print(type(prediction))\n",
    "  print(prediction.dtype)\n",
    "  return prediction[0] # new line\n",
    "  print('Ok')\n",
    "#   plt.figure(figsize=(12, 12))\n",
    "\n",
    "#   display_list = [test_input[0], prediction[0]]\n",
    "#   title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "#   for i in range(2):\n",
    "#     plt.subplot(1, 2, i+1)\n",
    "#     plt.title(title[i])\n",
    "#     # getting the pixel values between [0, 1] to plot it.\n",
    "#     plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "#     plt.axis('off')\n",
    "#   plt.show()\n",
    "#   return prediction # new line\n",
    "#   print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T04:38:48.236381Z",
     "iopub.status.busy": "2021-07-12T04:38:48.236016Z",
     "iopub.status.idle": "2021-07-12T04:38:51.556505Z",
     "shell.execute_reply": "2021-07-12T04:38:51.555711Z",
     "shell.execute_reply.started": "2021-07-12T04:38:48.23635Z"
    }
   },
   "outputs": [],
   "source": [
    "#predicted_all = np.zeros((5, 256, 256, 3), dtype=np.float32)\n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imsave\n",
    "\n",
    "index=0\n",
    "# Run the trained model on the test dataset\n",
    "for inp in train_hem.take(100):\n",
    "   im = generate_images(generator_f, inp)\n",
    "   #print('Returned: ', type(im))\n",
    "   #print('Returned: ', im.dtype)\n",
    "   #print('Returned: ', im.shape)\n",
    "   im = im.numpy()\n",
    "   #print('Returned: ', type(im))\n",
    "   #im  = im[0,:,:,:]\n",
    "   im = im * 0.5 + 0.5\n",
    "   #print('Returned: ', im.dtype) \n",
    "   imshow(im)\n",
    "   #break\n",
    "#    break\n",
    "#    print('Returned: ', im.shape)\n",
    "#    print(np.max(im), np.min(im)) \n",
    "#    im = im * 0.5 + 0.5\n",
    "#    print(np.max(im), np.min(im)) \n",
    "   #predicted_all[index] = im \n",
    "   #path = 'E:/Leuk study re-designed/C-NMC/Low imbalance/Cyclegan Oversample/all' + '/' + str(index) + '.bmp'\n",
    "   path = 'F:/rzbz/Leuk study re-designed/ALLIDB-2/High imbalance/Train - 1 to 100 ratio/Cyclegan Oversample/all' + '/' + hem_list[index][:-4] + '_syn.bmp'\n",
    "   imsave(path, im)\n",
    "   index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hem_list[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.io import imread, imsave, imshow\n",
    "im = imread(r'D:\\Leuk Dataset\\CycleGanOverSampled Data\\train\\hem\\0.bmp')\n",
    "print(im.shape)\n",
    "print(np.unique(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g.save('C:/Users/User/generator_g_at_50_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T04:39:33.262831Z",
     "iopub.status.busy": "2021-07-12T04:39:33.262483Z",
     "iopub.status.idle": "2021-07-12T04:39:33.471526Z",
     "shell.execute_reply": "2021-07-12T04:39:33.470724Z",
     "shell.execute_reply.started": "2021-07-12T04:39:33.262801Z"
    }
   },
   "outputs": [],
   "source": [
    "imshow(predicted_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predicted_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(predicted_all[0]), np.min(predicted_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im  = predicted_all[0]\n",
    "im = im * 255.0\n",
    "im = im.astype('uint8')\n",
    "imshow(im)\n",
    "print(np.unique(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.load_weights(r'C:\\Users\\User\\generator_g_at_50_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = 'E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\Train - 1 to 10 ratio\\all\\Im030_1.tif'\n",
    "path[:-4] + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "src_dir = r\"E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\Train - 1 to 10 ratio\\all\"\n",
    "dst_dir = r\"E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\CycleGanOversample testing\\train\\all\"\n",
    "for jpgfile in glob.iglob(os.path.join(src_dir, \"*.tif\")):\n",
    "    print(jpgfile)\n",
    "    shutil.copy(jpgfile[:-4] + '.png', dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "src_directory = r'E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\Train - 1 to 10 ratio\\hem'\n",
    "tar_direc = r'E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\CycleGanOversample testing\\train\\hem'\n",
    "c=1\n",
    "dir_list = os.listdir(src_directory)\n",
    "dir_list.sort()\n",
    "for filename in os.listdir(src_directory):\n",
    "#     print(filename)\n",
    "    if filename.endswith(\".tif\"):\n",
    "        im = Image.open(os.path.join(src_directory, filename))\n",
    "        name='img'+str(c)+'.png'\n",
    "        rgb_im = im.convert('RGB')\n",
    "#         print(os.path.join(tar_direc, dir_list[c-1][:-3] + 'png'))\n",
    "        rgb_im.save(os.path.join(tar_direc, dir_list[c-1][:-3] + 'bmp'))\n",
    "#        rgb_im.save(dir_list[:-3] + 'png')\n",
    "        c+=1\n",
    "#         print(os.path.join(directory, filename))\n",
    "        continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'Im030_1.tif'\n",
    "if p.endswith(\".tif\"):\n",
    "    print('Ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
