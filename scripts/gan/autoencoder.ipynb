{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf156139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b2d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db4171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0bcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe5999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2af1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca80eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = r'E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\Train - 1 to 10 ratio\\all'\n",
    "\n",
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.io import imread, imshow\n",
    "data = []\n",
    "i = 0\n",
    "CATEGORIES = r'all'\n",
    "plt.figure(figsize=(15, 15))\n",
    "#for category in CATEGORIES:\n",
    "#path = os.path.join(TRAIN_PATH, category)\n",
    "#print(path)\n",
    "list_img = os.listdir(TRAIN_PATH)\n",
    "#print(list_img)\n",
    "for img in list_img:\n",
    "    img_path = os.path.join(TRAIN_PATH, img)\n",
    "    print(img_path)\n",
    "\n",
    "    #label = CATEGORIES.index(category)\n",
    "    arr = imread(img_path)\n",
    "    #imshow(arr)\n",
    "    #break\n",
    "    #crop_arr = crop_center(arr, (210,210))\n",
    "    #if 1 <= i+1 <= 140:                      # total 140 image\n",
    "    #    ax = plt.subplot(13, 11, i+1)\n",
    "    #plt.imshow(arr)\n",
    "    #i += 1\n",
    "    data.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022dd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22825e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "x_train = []\n",
    "#y_train = []\n",
    "\n",
    "for features in data:\n",
    "    x_train.append(features)\n",
    "    #y_train.append(label)\n",
    "\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "#y_train = np.array(y_train)\n",
    "print(x_train.shape)\n",
    "print(x_train.dtype)\n",
    "\n",
    "r=c=452\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "new_x_train = np.zeros((x_train.shape[0], r, c, 3), dtype=np.uint8)\n",
    "print(new_x_train.shape)\n",
    "i=0\n",
    "for img in x_train:\n",
    "    image = resize(img,(r, c, 3), preserve_range=True)\n",
    "    new_x_train[i] = image\n",
    "    i+=1\n",
    "    #print(i)\n",
    "\n",
    "new_x_train = new_x_train/255.0\n",
    "new_x_train = new_x_train.astype('float32')\n",
    "print(new_x_train.shape)\n",
    "print(new_x_train.dtype)\n",
    "\n",
    "\n",
    "#np.save(\"x_train_leuknet\",x_train)\n",
    "#np.save(\"y_train_leuknet\",y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.io import imread, imshow\n",
    "imshow(new_x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d5b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Permute, multiply\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def squeeze_excite_block(tensor, ratio=16):\n",
    "    init = tensor\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init.shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0c9de",
   "metadata": {},
   "source": [
    "# Original net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eafb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Original net\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_img = keras.Input(shape=(452, 452, 3))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = squeeze_excite_block(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='Adagrad', loss='binary_crossentropy') #metrics=['accuracy']\n",
    "autoencoder.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca737520",
   "metadata": {},
   "source": [
    "# Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "#Original net\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_img = keras.Input(shape=(452, 452, 3))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer=\"he_normal\")(input_img)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer=\"he_normal\")(x)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer=\"he_normal\")(x)\n",
    "x = squeeze_excite_block(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer=\"he_normal\")(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same', kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same', kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='Adam', loss='binary_crossentropy') #metrics=['accuracy']\n",
    "autoencoder.summary()\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Modified\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_img = keras.Input(shape=(252, 252, 3))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "#x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "#x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "autoencoder.summary()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8cf071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Big-one\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_img = keras.Input(shape=(r, c, 3))\n",
    "\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (2, 2, 8) i.e. 32-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "#from t.keras.optimizers import Adam, RMSprop, SGD\n",
    "adam_opt = tf.keras.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-4)\n",
    "#sgd_opt = tf.keras.optimizers.SGD(lr=1e-06, momentum=0.9, decay=0.0, nesterov=False)\n",
    "#rmsp_opt = tf.keras.optimizers.RMSprop(lr=1e-4, decay=0.9)\n",
    "# eve_opt = Eve(lr=1e-4, decay=1E-4, beta_1=0.9, beta_2=0.999, beta_3=0.999, small_k=0.1, big_K=10, epsilon=1e-08)\n",
    "\n",
    "autoencoder.compile(optimizer= adam_opt,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945e2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "import tensorflow.keras as keras\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('train_norm_autoencoder_200.h5', monitor='loss', save_best_only=True, mode='min'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.0, verbose=1, patience=5, mode='max')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d60f6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "#dataAugmentaion = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c79230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "autoencoder.fit(dataAugmentaion.flow(new_x_train, new_x_train, batch_size = 2),\n",
    "                epochs=200,\n",
    "                #batch_size=128,\n",
    "                shuffle=True,\n",
    "                callbacks = callbacks)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "\n",
    "autoencoder.fit(new_x_train, new_x_train,\n",
    "                epochs=500,\n",
    "                batch_size=4,\n",
    "                shuffle=True,\n",
    "                callbacks = callbacks)\n",
    "                #validation_data=(x_test, x_test))\n",
    "                #callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "from skimage.io import imsave, imshow\n",
    "from skimage.transform import resize\n",
    "model = tf.keras.models.load_model('./train_norm_autoencoder_200.h5')\n",
    "#model = autoencoder\n",
    "\n",
    "img_names = os.listdir(r'D:\\new_leuk\\Leukemia_Work_Revive\\dataset\\val\\all')\n",
    "print(type(model))\n",
    "\n",
    "test_preds = np.zeros((new_x_train.shape[0], new_x_train.shape[1], new_x_train.shape[2], new_x_train.shape[3]), dtype=np.float32)\n",
    "'''\n",
    "'''\n",
    "for x in range(new_x_train.shape[0]):\n",
    "    x_test = new_x_train[x]\n",
    "    x_test = np.expand_dims(x_test, axis=0)\n",
    "\n",
    "    test_preds[x] = autoencoder.predict(x_test)\n",
    "    print(type(test_preds[x]))\n",
    "    print(test_preds[x].shape)\n",
    "    \n",
    "    #imshow(test_preds[x])\n",
    "    \n",
    "    #break\n",
    "    \n",
    "    print(img_names[x][:-4])\n",
    "    path = 'D:/new_leuk/Leukemia_Work_Revive/Autoencoder oversample data/val/all' + '/' + img_names[x][:-4] + '_syn.bmp'\n",
    "    print(path)\n",
    "    imsave(path, resize(test_preds[x].astype('float32'), (450, 450, 3), preserve_range=True))\n",
    "    if x==4:\n",
    "        break\n",
    "''' \n",
    "   \n",
    "    \n",
    "\n",
    "'''\n",
    "x_test = new_x_train[50]\n",
    "imshow(new_x_train[50])\n",
    "x_test = np.expand_dims(x_test, axis=0)\n",
    "x_test.shape\n",
    "\n",
    "nx_test = x_test[0,:,:,:]\n",
    "nx_test.shape\n",
    "imshow(nx_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('./final_hem_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b37edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''''\n",
    "import tensorflow as tf\n",
    "from skimage.io import imsave, imshow\n",
    "from skimage.transform import resize\n",
    "model = tf.keras.models.load_model('./final_hem_autoencoder.h5')\n",
    "#model = tf.keras.models.load_model('train_norm_autoencoder_200.h5')\n",
    "#model = autoencoder\n",
    "\n",
    "img_names = os.listdir(r'E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\Train - 1 to 10 ratio\\all')\n",
    "img_names.sort()\n",
    "print(type(model))\n",
    "\n",
    "\n",
    "\n",
    "PATH = r'E:\\Leuk study re-designed\\ALLIDB-2\\Low imbalance\\Train - 1 to 10 ratio\\all'\n",
    "import skimage \n",
    "from skimage.io import imread\n",
    "\n",
    "set_test = np.zeros((338,452,452,3), dtype=np.uint8) #hem batch 648,  #all batch 1,219\n",
    "for x in range(len(img_names)):\n",
    "    img = imread(os.path.join(PATH, img_names[x]))\n",
    "    img = resize(img,(new_x_train.shape[1], new_x_train.shape[2], new_x_train.shape[3]), preserve_range=True)\n",
    "    set_test[x] = img\n",
    "\n",
    "set_test = set_test/255.0\n",
    "set_test = set_test.astype('float32')\n",
    "print(set_test.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "test_preds = np.zeros((new_x_train.shape[0], new_x_train.shape[1], new_x_train.shape[2], new_x_train.shape[3]), dtype=np.float32)\n",
    "\n",
    "\n",
    "for x in range(new_x_train.shape[0]):\n",
    "    x_test = set_test[x]\n",
    "    #x_test = new_x_train[x]\n",
    "    x_test = np.expand_dims(x_test, axis=0)\n",
    "\n",
    "    test_preds[x] = autoencoder.predict(x_test)\n",
    "    #test_preds[x] = model.predict(x_test)\n",
    "    print(type(test_preds[x]))\n",
    "    print(test_preds[x].shape)\n",
    "    \n",
    "    #imshow(test_preds[x])\n",
    "    \n",
    "    #break\n",
    "    #'''\n",
    "    print(img_names[x][:-4])\n",
    "    path = 'E:/Leuk study re-designed/ALLIDB-2/Low imbalance/CycleGan Oversample/all' + '/' + img_names[x][:-4] + '_syn.tif'\n",
    "    print(path)\n",
    "    imsave(path, resize(test_preds[x].astype('float32'), (450, 450, 3), preserve_range=True))\n",
    "    #if x==4:\n",
    "    #    break\n",
    "    #''' \n",
    "   \n",
    "    \n",
    "\n",
    "'''\n",
    "x_test = new_x_train[50]\n",
    "imshow(new_x_train[50])\n",
    "x_test = np.expand_dims(x_test, axis=0)\n",
    "x_test.shape\n",
    "\n",
    "nx_test = x_test[0,:,:,:]\n",
    "nx_test.shape\n",
    "imshow(nx_test)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
