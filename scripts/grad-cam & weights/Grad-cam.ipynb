{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6ed669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0111a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import skimage\n",
    "from skimage.io import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bd384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "'''loading model'''\n",
    "root_dir = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High'\n",
    "model_name = r'EffNetB0_mcc_loss_high.h5'\n",
    "model = keras.models.load_model(os.path.join(root_dir, model_name))\n",
    "last_conv_layer_name = \"top_activation\"\n",
    "print(model.layers[-1].name)\n",
    "#model.layers[-1].activation = None\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8adb3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f6b304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(array, heatmap, orig_name, img_class, alpha):\n",
    "    # Load the original image\n",
    "    #img = keras.preprocessing.image.load_img(img_path)\n",
    "    #img = keras.preprocessing.image.img_to_array(img)\n",
    "    img = array\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    \n",
    "    #'''my addition'''\n",
    "    #test_img = superimposed_img\n",
    "    \n",
    "    #'''my addition'''\n",
    "    #superimposed_img = superimposed_img[0,:,:,:]\n",
    "    \n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    \n",
    "    #'''my addition'''\n",
    "    #test = np.array(superimposed_img)\n",
    "    #print(type(test))\n",
    "    \n",
    "    # Save the superimposed image\n",
    "    if img_class == 0:\n",
    "        path = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\diffrent approach heatmap\\all'\n",
    "        orig_name = orig_name[:-4]\n",
    "        orig_name = orig_name + '.png'\n",
    "        superimposed_img.save(os.path.join(path, orig_name))\n",
    "    else:\n",
    "        path = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\diffrent approach heatmap\\hem'\n",
    "        orig_name = orig_name[:-4]\n",
    "        orig_name = orig_name + '.png'\n",
    "        superimposed_img.save(os.path.join(path, orig_name))\n",
    "\n",
    "    # Display Grad CAM\n",
    "    #display(Image(cam_path))\n",
    "    #return test_img\n",
    "\n",
    "\n",
    "#arr = array[0,:,:,:]\n",
    "#result = save_and_display_gradcam(arr, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01d47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, bounding):\n",
    "    start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))\n",
    "    end = tuple(map(operator.add, start, bounding))\n",
    "    slices = tuple(map(slice, start, end))\n",
    "    im = img[slices].astype('float32')\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9147fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_ALL_PATH = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\Test\\all'\n",
    "VAL_HEM_PATH = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\Test\\hem'\n",
    "\n",
    "all_list = os.listdir(VAL_ALL_PATH) \n",
    "hem_list = os.listdir(VAL_HEM_PATH)\n",
    "\n",
    "all_list.sort()\n",
    "hem_list.sort()\n",
    "\n",
    "# for x in range(len(all_list)):\n",
    "#     img = imread(os.path.join(VAL_ALL_PATH, all_list[x]))\n",
    "#     cropped_img = crop_center(img, (150,150,3))\n",
    "#     rescaled_cropped_img = cropped_img * (1./255.)\n",
    "#     array = np.expand_dims(rescaled_cropped_img, axis=0)\n",
    "#     heatmap = make_gradcam_heatmap(array, model, last_conv_layer_name)\n",
    "#     save_and_display_gradcam(rescaled_cropped_img, heatmap, all_list[x], 0, 0.4)\n",
    "        \n",
    "# for x in range(len(hem_list)):\n",
    "#     img = imread(os.path.join(VAL_HEM_PATH, hem_list[x]))\n",
    "#     cropped_img = crop_center(img, (150,150,3))\n",
    "#     rescaled_cropped_img = cropped_img * (1./255.)\n",
    "#     array = np.expand_dims(rescaled_cropped_img, axis=0)\n",
    "#     heatmap = make_gradcam_heatmap(array, model, last_conv_layer_name)\n",
    "#     save_and_display_gradcam(rescaled_cropped_img, heatmap, hem_list[x], 1, 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf73bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5b2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c017f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979c481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29820add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1c6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58badb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3330f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde67bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ca1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b4aee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46448465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage \n",
    "from skimage.io import imread, imshow\n",
    "img_all = imread(r'D:\\new_leuk\\Leukemia_Work_Revive\\Corrected\\Originall data\\val\\all\\2.bmp')\n",
    "print('MAx: ', np.max(img_all))\n",
    "print('MIN: ', np.min(img_all))\n",
    "cropped_img_all = crop_center(img_all, (150,150,3))\n",
    "print('Cropped_img MAx: ', np.max(cropped_img_all))\n",
    "print('Cropped_img MIN: ', np.min(cropped_img_all))\n",
    "cropped_img_all = cropped_img_all.astype('uint8')\n",
    "print(cropped_img_all.dtype)\n",
    "imshow(cropped_img_all)\n",
    "rescaled_cropped_img_all = cropped_img_all * (1.0/255.0)\n",
    "print('Rescaled_cropped_img MAx: ', np.max(rescaled_cropped_img_all))\n",
    "print('Resclased_cropped_img MIN: ', np.min(rescaled_cropped_img_all))\n",
    "print(type(rescaled_cropped_img_all))\n",
    "print(rescaled_cropped_img_all.shape)\n",
    "print(rescaled_cropped_img_all.dtype)\n",
    "array = np.expand_dims(rescaled_cropped_img_all, axis=0)\n",
    "print(array.dtype, array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa64aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage \n",
    "from skimage.io import imread, imshow\n",
    "img_all = imread(r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\Test\\all\\Im003_1.tif')\n",
    "print('MAx: ', np.max(img_all))\n",
    "print('MIN: ', np.min(img_all))\n",
    "cropped_img_all = crop_center(img_all, (150,150,3))\n",
    "print('Cropped_img MAx: ', np.max(cropped_img_all))\n",
    "print('Cropped_img MIN: ', np.min(cropped_img_all))\n",
    "cropped_img_all = cropped_img_all.astype('uint8')\n",
    "print(cropped_img_all.dtype)\n",
    "imshow(cropped_img_all)\n",
    "rescaled_cropped_img_all = cropped_img_all * (1.0/255.0)\n",
    "print('Rescaled_cropped_img MAx: ', np.max(rescaled_cropped_img_all))\n",
    "print('Resclased_cropped_img MIN: ', np.min(rescaled_cropped_img_all))\n",
    "print(type(rescaled_cropped_img_all))\n",
    "print(rescaled_cropped_img_all.shape)\n",
    "print(rescaled_cropped_img_all.dtype)\n",
    "array = np.expand_dims(rescaled_cropped_img_all, axis=0)\n",
    "print(array.dtype, array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f10851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "root_dir = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High'\n",
    "model_name = r'EffNetB0_mcc_loss_high.h5'\n",
    "'''loading model'''\n",
    "# model = model.load_weights(os.path.join(root_dir, model_name))\n",
    "model = keras.models.load_model(os.path.join(root_dir, model_name), compile=False)\n",
    "model.summary()\n",
    "print(model.layers[-1].name)\n",
    "last_conv_layer_name = \"conv5_block16_concat\"        # Foe EfficientB0\n",
    "# last_conv_layer_name = \"conv5_block16_concat\"  #For Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed41d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf-explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import explainer\n",
    "import tf_explain\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "\n",
    "# Instantiation of the explainer\n",
    "explainer = GradCAM()\n",
    "\n",
    "arr = array[0,:,:,:]\n",
    "data = ([arr], None)\n",
    "# Call to explain() method\n",
    "output = explainer.explain(data, model, class_index=0, layer_name='conv5_block16_concat', colormap=cv2.COLORMAP_JET)\n",
    "\n",
    "# output_dir = r'D:\\new_leuk\\Leukemia_Work_Revive\\Corrected\\Grad-cam heatmap'\n",
    "# output_name = 'test2.png'\n",
    "\n",
    "# Save output\n",
    "#explainer.save(output, output_dir, output_name)\n",
    "\n",
    "for x in range(len(all_list)):\n",
    "    img = imread(os.path.join(VAL_ALL_PATH, all_list[x]))\n",
    "    cropped_img = crop_center(img, (150,150,3))\n",
    "    rescaled_cropped_img = cropped_img * (1./255.)\n",
    "    data = ([rescaled_cropped_img], None)\n",
    "    output = explainer.explain(data, model, class_index=0, layer_name='conv5_block16_concat', colormap=cv2.COLORMAP_JET)\n",
    "    output_dir = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\Low\\corresponding hetmaps\\all'\n",
    "    output_name = all_list[x]\n",
    "    output_name = output_name[:-4]\n",
    "    output_name = output_name + '.png'\n",
    "    explainer.save(output, output_dir, output_name)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7698c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6a858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dedc947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e8384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710aba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c13b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.io import imshow, imread\n",
    "print(len(all_list))\n",
    "for x in all_list:\n",
    "    single_orig_image = imread(os.path.join(VAL_ALL_PATH, x))\n",
    "    single_cropped_img = crop_center(single_orig_image, (210,210,3))\n",
    "    single_cropped_img_dim_extended = np.expand_dims(single_cropped_img, axis=0)\n",
    "    pred_value = model.predict(single_cropped_img_dim_extended)\n",
    "    print(x, pred_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64661e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad8d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b50f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89ef3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36471b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fd0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985320da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efba6c8b",
   "metadata": {},
   "source": [
    "# All In One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import skimage\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "\n",
    "def crop_center(img, bounding):\n",
    "    start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))\n",
    "    end = tuple(map(operator.add, start, bounding))\n",
    "    slices = tuple(map(slice, start, end))\n",
    "    im = img[slices].astype('float32')\n",
    "    return im\n",
    "\n",
    "VAL_ALL_PATH = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\Test\\all'\n",
    "VAL_HEM_PATH = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\Test\\hem'\n",
    "\n",
    "# VAL_ALL_PATH = r'F:\\Leuk study re-designed\\C-NMC best model\\High\\Test enhanched\\all'\n",
    "# VAL_HEM_PATH = r'F:\\Leuk study re-designed\\C-NMC best model\\High\\Test enhanched\\hem'\n",
    "\n",
    "all_list = os.listdir(VAL_ALL_PATH) \n",
    "hem_list = os.listdir(VAL_HEM_PATH)\n",
    "\n",
    "all_list.sort()\n",
    "hem_list.sort()\n",
    "\n",
    "\n",
    "'''FIX THESE PARAMETER'''\n",
    "# PATH = VAL_ALL_PATH\n",
    "# LIST = all_list\n",
    "\n",
    "PATH = VAL_HEM_PATH\n",
    "LIST = hem_list\n",
    "\n",
    "# root_dir = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High'   # ALLIDB-2 High root\n",
    "root_dir = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\Low'    # ALLIDB-2 Low root\n",
    "\n",
    "# root_dir = r'F:\\Leuk study re-designed\\C-NMC best model\\High'       # C-NMC High root\n",
    "# root_dir = r'F:\\Leuk study re-designed\\C-NMC best model\\Low'        # C-NMC Low root\n",
    "\n",
    "# model_name = r'HRD_EfficientNetB0_MccLoss_test1.h5'    # C-NMC High model\n",
    "# model_name = r'LRD_DesnseNet121_weighted_test1.h5'     # C-NMC Low model\n",
    "\n",
    "# model_name = r'EffNetB0_mcc_loss_high.h5'              # ALLIDB-2 High model\n",
    "model_name = r'DenseNet121_low_class_weight.h5'        # ALLIDB-2 Low model\n",
    "\n",
    "# last_conv_layer_name = \"top_activation\"        # For EfficientNetBo\n",
    "last_conv_layer_name = \"conv5_block16_concat\"    #For densenet121\n",
    "\n",
    "out_dir = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\Low\\corresponding hetmaps\\hem'\n",
    "index = 0  #Index of ouput layer    0 = all,,   1 = hem\n",
    "\n",
    "crop_height = 150\n",
    "crop_width = 150\n",
    "'''END'''\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import skimage \n",
    "from skimage.io import imread, imshow\n",
    "img_all = imread(os.path.join(PATH, LIST[0]))\n",
    "# img_all = imread(r'F:\\Leuk study re-designed\\C-NMC best model\\High\\Test enhanched\\hem\\4.bmp')\n",
    "print('MAx: ', np.max(img_all))\n",
    "print('MIN: ', np.min(img_all))\n",
    "cropped_img_all = crop_center(img_all, (crop_height,crop_width,3))\n",
    "print('Cropped_img MAx: ', np.max(cropped_img_all))\n",
    "print('Cropped_img MIN: ', np.min(cropped_img_all))\n",
    "cropped_img_all = cropped_img_all.astype('uint8')\n",
    "print(cropped_img_all.dtype)\n",
    "imshow(cropped_img_all)\n",
    "rescaled_cropped_img_all = cropped_img_all * (1.0/255.0)\n",
    "print('Rescaled_cropped_img MAx: ', np.max(rescaled_cropped_img_all))\n",
    "print('Resclased_cropped_img MIN: ', np.min(rescaled_cropped_img_all))\n",
    "print(type(rescaled_cropped_img_all))\n",
    "print(rescaled_cropped_img_all.shape)\n",
    "print(rescaled_cropped_img_all.dtype)\n",
    "array = np.expand_dims(rescaled_cropped_img_all, axis=0)\n",
    "print(array.dtype, array.shape)\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "# root_dir = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High'\n",
    "# model_name = r'EffNetB0_mcc_loss_high.h5'\n",
    "'''loading model'''\n",
    "# model = model.load_weights(os.path.join(root_dir, model_name))\n",
    "model = keras.models.load_model(os.path.join(root_dir, model_name), compile=False)\n",
    "model.summary()\n",
    "print(model.layers[-1].name)\n",
    "# last_conv_layer_name = \"conv5_block16_concat\"        # Foe EfficientB0\n",
    "# last_conv_layer_name = \"conv5_block16_concat\"  #For Densenet121\n",
    "\n",
    "\n",
    "#pip install tf-explain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import explainer\n",
    "import tf_explain\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "\n",
    "# Instantiation of the explainer\n",
    "explainer = GradCAM()\n",
    "\n",
    "arr = array[0,:,:,:]\n",
    "data = ([arr], None)\n",
    "# Call to explain() method\n",
    "output = explainer.explain(data, model, class_index=index, layer_name=last_conv_layer_name, colormap=cv2.COLORMAP_JET)\n",
    "\n",
    "# output_dir = r'D:\\new_leuk\\Leukemia_Work_Revive\\Corrected\\Grad-cam heatmap'\n",
    "# output_name = 'test2.png'\n",
    "\n",
    "# Save output\n",
    "#explainer.save(output, output_dir, output_name)\n",
    "\n",
    "for x in range(len(LIST)):\n",
    "    img = imread(os.path.join(PATH, LIST[x]))\n",
    "    cropped_img = crop_center(img, (crop_height,crop_width,3))\n",
    "    rescaled_cropped_img = cropped_img * (1./255.)\n",
    "    data = ([rescaled_cropped_img], None)\n",
    "    output = explainer.explain(data, model, class_index=index, layer_name=last_conv_layer_name, colormap=cv2.COLORMAP_JET)\n",
    "    output_dir = out_dir\n",
    "    output_name = LIST[x]\n",
    "    output_name = output_name[:-4]\n",
    "    output_name = output_name + '.png'\n",
    "    explainer.save(output, output_dir, output_name)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.io import imshow, imread, imsave\n",
    "print(len(LIST))\n",
    "pred_list = []\n",
    "for x in LIST:\n",
    "    single_orig_image = imread(os.path.join(PATH, x))\n",
    "    single_cropped_img = crop_center(single_orig_image, (crop_height,crop_width,3))\n",
    "    single_cropped_img_dim_extended = np.expand_dims(single_cropped_img, axis=0)\n",
    "    single_cropped_img_dim_extended = single_cropped_img_dim_extended / 255.0\n",
    "    pred_value = model.predict(single_cropped_img_dim_extended)\n",
    "    print(x, pred_value)\n",
    "    if pred_value > 0.5:\n",
    "        pred_list.append(1)\n",
    "        pred_flat = 1\n",
    "    else:\n",
    "        pred_list.append(0)\n",
    "        pred_flat = 0\n",
    "    des_path = out_dir + '/' + x[:-4] + '_' + str(pred_flat) + '.png'\n",
    "    imsave(des_path, single_cropped_img)\n",
    "    \n",
    "\n",
    "print('Number of 0 :', pred_list.count(0))\n",
    "print('Number of 1 :', pred_list.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3be070",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = '1037_1.png'\n",
    "l[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = r'F:\\Leuk study re-designed\\C-NMC best model\\High\\corresponding heatmaps\\all'\n",
    "all_images = os.listdir(path)\n",
    "all_images.sort()\n",
    "all_images\n",
    "#''\n",
    "target_path0 = r'F:\\Leuk study re-designed\\C-NMC best model\\High\\corresponding heatmaps\\all\\classsified'\n",
    "target_path1 = r'F:\\Leuk study re-designed\\C-NMC best model\\High\\corresponding heatmaps\\all\\misclasssified'\n",
    "\n",
    "for x in range (len(all_images)):\n",
    "    if all_images[x][-5:-4] == 0:\n",
    "        orig = imread(os.path.join(path, all_images[x]))\n",
    "        final_path = target_path0 + '/' + all_images[x] \n",
    "        imsave(final_path, orig)\n",
    "        print(all_images[x][:-6])\n",
    "        name = all_images[x][:-6] + '.png'\n",
    "        print('name: ', name)\n",
    "        heatmap = imread(os.path.join(path, name))\n",
    "        final_path = target_path0 + '/' + all_images[x][:-6] + '.png'\n",
    "        imsave(final_path, heatmap)\n",
    "    else:\n",
    "        orig = imread(os.path.join(path, all_images[x]))\n",
    "        final_path = target_path1 + '/' + all_images[x] \n",
    "        imsave(final_path, orig)\n",
    "        print(all_images[x])\n",
    "        print(all_images[x][:-6])\n",
    "        name = all_images[x][:-6] + '.png'\n",
    "        print('name: ', name)\n",
    "        heatmap = imread(os.path.join(path, name))\n",
    "        final_path = target_path1 + '/' + all_images[x][:-6] + '.png'\n",
    "        imsave(final_path, heatmap)\n",
    "#''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '134sdfdfd.png'\n",
    "b = '_0.png'\n",
    "print(a[:-4])\n",
    "print(b[-5:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ebcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\corresponding hetmaps\\all'\n",
    "all_images = os.listdir(path)\n",
    "# all_images.sort()\n",
    "# print(len(all_images)/2)\n",
    "\n",
    "heatmap = []\n",
    "orig = []\n",
    "for x in all_images:\n",
    "    if '_' not in x:\n",
    "        heatmap.append(x)\n",
    "    else:\n",
    "        orig.append(x)\n",
    "print(len(heatmap))\n",
    "print(len(orig))\n",
    "\n",
    "target_path0 = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\corresponding hetmaps\\all classified'\n",
    "target_path1 = r'F:\\Leuk study re-designed\\ALLIDB-2 best models\\High\\corresponding hetmaps\\all misclassified'\n",
    "\n",
    "\n",
    "for x in heatmap:\n",
    "    for y in orig:\n",
    "        if x[:-4] == y[:-6]:  \n",
    "            print(x, y)\n",
    "#             print(y[-5:-4])\n",
    "            if y[-5:-4] == '0':\n",
    "                print('Classified')\n",
    "                htmap = imread(os.path.join(path, x))\n",
    "                final_path = target_path0 + '/' + x\n",
    "                print(final_path)\n",
    "                imsave(final_path, htmap)\n",
    "                \n",
    "                original = imread(os.path.join(path, y))\n",
    "                final_path = target_path0 + r'/' + y \n",
    "                imsave(final_path, original)\n",
    "            elif y[-5:-4] == '1':\n",
    "                print('misclassified')\n",
    "                htmap = imread(os.path.join(path, x))\n",
    "                final_path = target_path1 + r'/' + x\n",
    "                print(final_path)\n",
    "                imsave(final_path, htmap)\n",
    "                \n",
    "                original = imread(os.path.join(path, y))\n",
    "                final_path = target_path1 + r'/' + y \n",
    "                imsave(final_path, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8de3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leukemia",
   "language": "python",
   "name": "leukemia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
