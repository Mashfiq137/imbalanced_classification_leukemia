{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc56ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb13351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a83d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline    \n",
    "import operator   \n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd00ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r'D:\\Leuk Dataset\\new fol\\train'\n",
    "VAL_DIRECTORY = r'D:\\Leuk Dataset\\new fol\\val'\n",
    "\n",
    "CATEGORIES = ['all', 'hem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2115566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, bounding):\n",
    "    start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))\n",
    "    end = tuple(map(operator.add, start, bounding))\n",
    "    slices = tuple(map(slice, start, end))\n",
    "    return img[slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "i = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path)\n",
    "        crop_arr = crop_center(arr, (150,150))\n",
    "        if 1 <= i+1 <= 140:                      # total 140 image\n",
    "            ax = plt.subplot(13, 11, i+1)\n",
    "        plt.imshow(crop_arr)\n",
    "        i += 1\n",
    "        data.append([crop_arr, label])\n",
    "#         if i+1==3000:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for features, label in data:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "y_train = y_train / 255.0\n",
    "\n",
    "# np.save(\"x_train_leuknet\",x_train)\n",
    "# np.save(\"y_train_leuknet\",y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "i = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(VAL_DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path)\n",
    "        crop_arr = crop_center(arr, (150,150))\n",
    "        if 1 <= i+1 <= 70:                     # total image 70\n",
    "            ax = plt.subplot(10, 7, i+1)\n",
    "        plt.imshow(crop_arr)\n",
    "        i += 1\n",
    "        val_data.append([crop_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(val_data)\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for features, label in val_data:\n",
    "    x_val.append(features)\n",
    "    y_val.append(label)\n",
    "\n",
    "    \n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_val = x_val.astype('float32')\n",
    "y_val = y_val.astype('float32')\n",
    "\n",
    "x_val = x_val / 255.0\n",
    "y_val = y_val / 255.0\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "def get_model():\n",
    "    base_model = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=(150,150,3), \n",
    "        pooling=None,\n",
    "        classes=1,\n",
    "        classifier_activation=\"sigmoid\",\n",
    "    )\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    prediction = Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input,outputs=prediction)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8babf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagen = ImageDataGenerator(rescale=1./255)\n",
    "datagen = ImageDataGenerator()\n",
    "# datagen.fit(x_train)\n",
    "# type(x_train)\n",
    "# datagen.fit(x_val)\n",
    "# type(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    " for epoch in range(2):\n",
    "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=16):\n",
    "        #model.fit(x_batch, y_batch)\n",
    "        learner = ktrain.get_learner(model, train_data=(x_batch, y_batch), val_data = (x_val, y_val))\n",
    "        learner.autofit(0.001, 5, monitor='val_accuracy', reduce_on_plateau=5, reduce_factor=10, checkpoint_folder='F:\\EfficientNetB0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9462a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner = ktrain.get_learner(model, train_data=datagen.flow(x_train, y_train), val_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild the model to train from scratch \n",
    "#learner.set_model(get_model()) \n",
    "    \n",
    "# training using autofit\n",
    "#learner.autofit(0.001, 200, monitor='val_accuracy', reduce_on_plateau=5, reduce_factor=10, checkpoint_folder='F:\\EfficientNetB0')\n",
    "#learner.autofit(0.005, 2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
