{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff9f4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "259abb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os \n",
    "import time\n",
    "#import cv2\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "#import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "from keras.utils import np_utils\n",
    "#from imgaug import augmenters as iaa    \n",
    "import itertools\n",
    "%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "#from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "#from classification_models.keras import Classifiers\n",
    "# GPU test\n",
    "from tensorflow.python.client import device_lib\n",
    "np.random.seed(42)\n",
    "from keras.models import load_model\n",
    "# Print version\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.regularizers import l2\n",
    "import os, sys\n",
    "import scipy.misc\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random \n",
    "import shutil \n",
    "import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation,Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import load_model\n",
    "#from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd87b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r'D:\\Leuk Dataset\\new fol\\train'\n",
    "VAL_DIRECTORY = r'D:\\Leuk Dataset\\new fol\\val'\n",
    "\n",
    "CATEGORIES = ['all', 'hem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56f78e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, bounding):\n",
    "    start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))\n",
    "    end = tuple(map(operator.add, start, bounding))\n",
    "    slices = tuple(map(slice, start, end))\n",
    "    return img[slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327455b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "i = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path)\n",
    "        crop_arr = crop_center(arr, (210,210))\n",
    "        if 1 <= i+1 <= 140:                      # total 140 image\n",
    "            ax = plt.subplot(13, 11, i+1)\n",
    "        plt.imshow(crop_arr)\n",
    "        i += 1\n",
    "        data.append([crop_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828aa24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for features, label in data:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "np.save(\"x_train_leuknet\",x_train)\n",
    "np.save(\"y_train_leuknet\",y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d911b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "i = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(VAL_DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path)\n",
    "        crop_arr = crop_center(arr, (210,210))\n",
    "        if 1 <= i+1 <= 70:                     # total image 70\n",
    "            ax = plt.subplot(10, 7, i+1)\n",
    "        plt.imshow(crop_arr)\n",
    "        i += 1\n",
    "        val_data.append([crop_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "537f28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(val_data)\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for features, label in val_data:\n",
    "    x_val.append(features)\n",
    "    y_val.append(label)\n",
    "\n",
    "    \n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# load model without classifier layers\n",
    "model = ResNet50(include_top=False, input_shape=(210, 210, 3))\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "#class1 = Dense(1024, activation='relu')(flat1)\n",
    "#class2 = Dense(1024, activation='relu')(class1)\n",
    "output = Dense(1, activation='sigmoid')(flat1)\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "# summarize\n",
    "model.summary()\n",
    "'''\n",
    "def build_resnet50_unet(input_shape):\n",
    "\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    s = Lambda(lambda x: x/255) (inputs)\n",
    "\n",
    "    \"\"\" Pre-trained VGG16 Model \"\"\"\n",
    "    resnet50 = ResNet50(include_top=True, weights=None, input_tensor=s, input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1,\n",
    "    classifier_activation=\"sigmoid\")\n",
    "    \n",
    "    return resnet50\n",
    "\n",
    "     \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (210, 210, 3)\n",
    "    model = build_resnet50_unet(input_shape)\n",
    "    model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "569d896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)\n",
    "#sgd_opt = SGD(learning_rate=1e-06, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#rmsp_opt = RMSprop(lr=1e-4, decay=0.9)\n",
    "# eve_opt = Eve(lr=1e-4, decay=1E-4, beta_1=0.9, beta_2=0.999, beta_3=0.999, small_k=0.1, big_K=10, epsilon=1e-08)\n",
    "\n",
    "model.compile(optimizer= adam_opt,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2c5bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('weighted_baseline_ResNet50.h5', monitor='val_acc', save_best_only=True, mode='max'),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, verbose=1, patience=5, mode='max')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f328b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "'''\n",
    "x_train = x_train.astype('float32')\n",
    "x_val   = x_val.astype('float32')\n",
    "print(x_train.dtype)\n",
    "print(x_val.dtype)\n",
    "x_train = np.resize(x_train, (x_train.shape[0], 32, 32, 3))\n",
    "x_val = np.resize(x_val, (x_val.shape[0], 32, 32, 3))\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f35d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "BATCH_SIZE=32\n",
    "\n",
    "TRAINING_SIZE = x_train.shape[0]\n",
    "\n",
    "VALIDATION_SIZE = x_val.shape[0]\n",
    "\n",
    "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / BATCH_SIZE))\n",
    "train_steps_per_epoch = compute_steps_per_epoch(TRAINING_SIZE)\n",
    "val_steps = compute_steps_per_epoch(VALIDATION_SIZE)\n",
    "print(train_steps_per_epoch, val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52579601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dataAugmentaion = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ecd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(dataAugmentaion.flow(x_train, y_train, batch_size = 1),\n",
    " validation_data = (x_val,y_val), steps_per_epoch = len(x_train) // 1,\n",
    " epochs = 50, class_weight={0:0.73301705, 1:1.57288286})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aafb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
